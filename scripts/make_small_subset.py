"""
make_small_subset.py

Creates a reduced dataset for faster training by sampling a limited number of images
from each dataset group specified in manifest.csv.

Usage:
    python .\\scripts\\make_small_subset.py --manifest .\\data\\manifest.csv --out .\\data_small --max_per_dataset 2000
"""

import argparse
from pathlib import Path
import shutil

import pandas as pd
from tqdm import tqdm


def main():
    parser = argparse.ArgumentParser(description="Create smaller subset from manifest.csv")
    parser.add_argument("--manifest", required=True, help="Path to manifest.csv generated by merge_datasets.py")
    parser.add_argument("--out", required=True, help="Output directory for reduced dataset (e.g. data_small)")
    parser.add_argument("--max_per_dataset", type=int, default=2000, help="Max samples to keep per dataset name")
    args = parser.parse_args()

    manifest_path = Path(args.manifest)
    out_root = Path(args.out)

    df = pd.read_csv(manifest_path)

    # Expected columns from merge_datasets.py:
    # orig_filename, dst_image, dst_mask, dataset, split
    required_cols = {"dst_image", "dst_mask", "dataset", "split"}
    missing = required_cols.difference(df.columns)
    if missing:
        raise ValueError(f"Manifest missing required columns: {missing}. Got: {list(df.columns)}")

    print(f"Loaded manifest with {len(df)} total samples")

    out_images = out_root / "images"
    out_masks = out_root / "masks"

    # create base split dirs
    for split in ["train", "val", "test"]:
        (out_images / split).mkdir(parents=True, exist_ok=True)
        (out_masks / split).mkdir(parents=True, exist_ok=True)

    sampled_rows = []

    # Group by dataset (midv2020, midv500, smartdoc, iranian, etc.)
    for dataset_name, group in df.groupby("dataset"):
        sample_count = min(len(group), args.max_per_dataset)
        df_sampled = group.sample(n=sample_count, random_state=42)
        sampled_rows.append(df_sampled)
        print(f"Dataset: {dataset_name} -> selected {sample_count} samples")

        for _, row in tqdm(df_sampled.iterrows(), total=len(df_sampled), desc=f"Copying {dataset_name}"):
            img_src = Path(row["dst_image"])
            mask_src = Path(row["dst_mask"])
            split = row["split"]

            img_dst = out_images / split / img_src.name
            mask_dst = out_masks / split / mask_src.name

            img_dst.parent.mkdir(parents=True, exist_ok=True)
            mask_dst.parent.mkdir(parents=True, exist_ok=True)

            try:
                shutil.copy(img_src, img_dst)
                shutil.copy(mask_src, mask_dst)
            except Exception as e:
                print(f"[WARN] failed copy: {img_src} â€” {e}")

    final_df = pd.concat(sampled_rows).reset_index(drop=True)
    final_df.to_csv(out_root / "manifest_small.csv", index=False)
    print("\nSubset created successfully!")
    print(f"Output root: {out_root}")
    print(f"Total final samples: {len(final_df)}")


if __name__ == "__main__":
    main()
